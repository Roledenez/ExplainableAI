{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b852350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.gcptutorials.com/post/how-to-get-weights-of-layers-in-tensorflow\n",
    "# https://datascience.stackexchange.com/questions/85409/getting-nn-weights-for-every-batch-epoch-from-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8434fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0ea1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "\n",
    "start, stop = 1,100\n",
    "cnt = stop - start + 1\n",
    "xs = np.linspace(start, stop, num = cnt)\n",
    "b,k = 1,2\n",
    "ys = np.array([k*x + b for x in xs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6af2d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model with one feature and one unit for regression task\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=12, input_shape=[1], activation='relu'),\n",
    "    layers.Dense(units=128, input_shape=[1], activation='relu'),\n",
    "    layers.Dense(units=1, input_shape=[1], activation='relu')\n",
    "])\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "batch_size = int(cnt / 5)\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8240a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(6, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f636059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './hdf5/checkpoint-{epoch:02d}.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    save_freq ='epoch', # 1 for every batch\n",
    "    save_best_only=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "242d1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 95.2379\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 91.2242\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 87.3436\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 83.5259\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 79.7353\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 75.6827\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 71.4746\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 66.8123\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 61.9225\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.5916\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 50.8747\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.7368\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 37.6812\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 30.3267\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 22.3056\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 13.6158\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.0403\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 4.2996\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 5.6916\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.1497\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.0957\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 1.2161\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8966\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7371\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4756\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4059\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3955\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2224\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0958\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0746\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0693\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1912\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1470\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1729\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1839\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1840\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 921us/step - loss: 0.2038\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1710\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0968\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 892us/step - loss: 0.0876\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0805\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0941\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0831\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0789\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1446\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0959\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0808\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0678\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2023\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1167\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.2398\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3114\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1611\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3174\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3839\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3977\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1353\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0473\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0438\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0479\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.1499\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0718\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0801\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 985us/step - loss: 0.0757\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0886\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.2513\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2883\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 0.3655\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3847\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2765\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1583\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.1133\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2002\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2454\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2712\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1105\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1627\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2717\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2412\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "history = model.fit(xs, ys, batch_size=batch_size, epochs=epochs, \n",
    "                    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be2398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: \n",
      " <tf.Variable 'module_wrapper/dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.69388044]], dtype=float32)> \n",
      " Bias: \n",
      " <tf.Variable 'module_wrapper/dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.39999834], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "w, b = model.weights\n",
    "print(\"Weights: \\n {} \\n Bias: \\n {}\".format(w,b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80909956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read weights from h5 file\n",
    "import h5py\n",
    "\n",
    "def getH5Keys(fileName):\n",
    "\n",
    "    keys = []\n",
    "    with h5py.File(fileName, mode='r') as f:\n",
    "        for key in f:\n",
    "            keys.append(key)\n",
    "\n",
    "    return keys\n",
    "\n",
    "def isGroup(obj):\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def isDataset(obj):\n",
    "    if isinstance(obj, h5py.Dataset):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def getDataSetsFromGroup(datasets, obj):\n",
    "    if isGroup(obj):\n",
    "        for key in obj:\n",
    "            x = obj[key]\n",
    "            getDataSetsFromGroup(datasets, x)\n",
    "    else:\n",
    "        datasets.append(obj)\n",
    "\n",
    "\n",
    "def getWeightsForLayer(layerName, fileName):\n",
    "\n",
    "    weights = []\n",
    "    with h5py.File(fileName, mode='r') as f:\n",
    "        for key in f:\n",
    "            if layerName in key:\n",
    "                obj = f[key]\n",
    "                datasets = []\n",
    "                getDataSetsFromGroup(datasets, obj)\n",
    "\n",
    "                for dataset in datasets:\n",
    "                    w = np.array(dataset)\n",
    "                    weights.append(w)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be79bb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['module_wrapper_4', 'module_wrapper_5', 'module_wrapper_6']\n",
      "(128,)\n",
      "(12, 128)\n",
      "[array([ 0.05292301,  0.        ,  0.        , -0.04749306,  0.        ,\n",
      "       -0.04234662,  0.        , -0.04213697,  0.        , -0.01821099,\n",
      "        0.        ,  0.05441388,  0.05253087,  0.05335314, -0.02333801,\n",
      "       -0.04810073,  0.0532589 ,  0.        ,  0.        , -0.00500865,\n",
      "        0.05159298,  0.        , -0.04540244, -0.00749066,  0.05578383,\n",
      "        0.05513497,  0.02916982,  0.        ,  0.        ,  0.05271865,\n",
      "        0.05221001,  0.        ,  0.        ,  0.05181132,  0.05134611,\n",
      "        0.        , -0.0459338 ,  0.05282699,  0.        ,  0.        ,\n",
      "        0.0562271 ,  0.05439966,  0.        ,  0.        ,  0.        ,\n",
      "       -0.01690347,  0.        ,  0.05854054,  0.        , -0.04482976,\n",
      "       -0.0471217 , -0.01578558,  0.05172238,  0.        , -0.01820122,\n",
      "        0.05299278, -0.02303774,  0.        ,  0.00264466, -0.04832368,\n",
      "        0.        , -0.02059515,  0.05146533, -0.02630404, -0.03645641,\n",
      "       -0.01028267,  0.        ,  0.        ,  0.        , -0.02796407,\n",
      "        0.        ,  0.        ,  0.        , -0.04833061,  0.05167345,\n",
      "        0.05510562,  0.        , -0.02842459,  0.05212617,  0.05159394,\n",
      "        0.        ,  0.        ,  0.        , -0.0250474 , -0.01756254,\n",
      "        0.0521006 , -0.03052371,  0.05502861,  0.05185211,  0.        ,\n",
      "        0.05892892,  0.        ,  0.        ,  0.05225017,  0.05172504,\n",
      "        0.        ,  0.        ,  0.        , -0.01038107,  0.        ,\n",
      "       -0.03456163, -0.01925792,  0.        ,  0.        ,  0.        ,\n",
      "       -0.0483721 ,  0.        ,  0.        , -0.03990735,  0.        ,\n",
      "       -0.04780807, -0.04638761,  0.05322153,  0.        ,  0.        ,\n",
      "        0.        ,  0.0512822 , -0.02716686,  0.05283689,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.03624665,  0.05203821,  0.05171805], dtype=float32), array([[ 0.07081126, -0.05228047,  0.19241168, ...,  0.19782187,\n",
      "        -0.17181507,  0.18626265],\n",
      "       [-0.03886839, -0.15686655, -0.12451839, ...,  0.16374244,\n",
      "         0.22347635,  0.1337369 ],\n",
      "       [-0.04920769, -0.02497758, -0.12502095, ...,  0.16210736,\n",
      "         0.17100243,  0.07823898],\n",
      "       ...,\n",
      "       [-0.03394511,  0.1404001 ,  0.1323431 , ..., -0.10044509,\n",
      "         0.19126223,  0.20052119],\n",
      "       [ 0.19124989, -0.05751646,  0.00562985, ...,  0.13776118,\n",
      "        -0.07317246,  0.14756279],\n",
      "       [-0.05120715, -0.10227659, -0.07492952, ..., -0.01658836,\n",
      "         0.01900321,  0.11527337]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = './hdf5/checkpoint-10.hdf5'\n",
    "layers = getH5Keys(checkpoint_path)\n",
    "firstLayer = layers[1]\n",
    "print(layers) # ['dense']\n",
    "\n",
    "weights = getWeightsForLayer(firstLayer, checkpoint_path)\n",
    "for w in weights:\n",
    "    print(w.shape)\n",
    "print(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf3a9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "module_wrapper_4 (ModuleWrap (20, 12)                  24        \n",
      "_________________________________________________________________\n",
      "module_wrapper_5 (ModuleWrap (20, 128)                 1664      \n",
      "_________________________________________________________________\n",
      "module_wrapper_6 (ModuleWrap (20, 1)                   129       \n",
      "=================================================================\n",
      "Total params: 1,817\n",
      "Trainable params: 1,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f546d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "(1, 1)\n",
      "[array([0.8099931], dtype=float32), array([[1.1013573]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weights = getWeightsForLayer(firstLayer, checkpoint_path)\n",
    "for w in weights:\n",
    "    print(w.shape)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b96288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166d8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d429475",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = {}\n",
    "weight_callback = tf.keras.callbacks.LambdaCallback \\\n",
    "( on_epoch_end=lambda epoch, logs:  weights_dict.update({epoch:model.get_weights()}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f360789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "5/5 [==============================] - 0s 957us/step - loss: 66.4561\n",
      "Epoch 2/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 66.2068\n",
      "Epoch 3/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 65.9394\n",
      "Epoch 4/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 65.6836\n",
      "Epoch 5/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 65.4381\n",
      "Epoch 6/80\n",
      "5/5 [==============================] - 0s 990us/step - loss: 65.1785\n",
      "Epoch 7/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 64.9162\n",
      "Epoch 8/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 64.6734\n",
      "Epoch 9/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 64.4163\n",
      "Epoch 10/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 64.1527\n",
      "Epoch 11/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 63.9010\n",
      "Epoch 12/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 63.6385\n",
      "Epoch 13/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 63.3872\n",
      "Epoch 14/80\n",
      "5/5 [==============================] - 0s 828us/step - loss: 63.1263\n",
      "Epoch 15/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.8774\n",
      "Epoch 16/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 62.6204\n",
      "Epoch 17/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 62.3615\n",
      "Epoch 18/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 62.1083\n",
      "Epoch 19/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 61.8485\n",
      "Epoch 20/80\n",
      "5/5 [==============================] - 0s 400us/step - loss: 61.5913\n",
      "Epoch 21/80\n",
      "5/5 [==============================] - 0s 674us/step - loss: 61.3416\n",
      "Epoch 22/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 61.0871\n",
      "Epoch 23/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 60.8287\n",
      "Epoch 24/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 60.5735\n",
      "Epoch 25/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 60.3106\n",
      "Epoch 26/80\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 60.0585\n",
      "Epoch 27/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 59.8029\n",
      "Epoch 28/80\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 59.5395\n",
      "Epoch 29/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 59.2917\n",
      "Epoch 30/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 59.0384\n",
      "Epoch 31/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 58.7823\n",
      "Epoch 32/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 58.5258\n",
      "Epoch 33/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 58.2683\n",
      "Epoch 34/80\n",
      "5/5 [==============================] - 0s 396us/step - loss: 58.0122\n",
      "Epoch 35/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 57.7524\n",
      "Epoch 36/80\n",
      "5/5 [==============================] - 0s 472us/step - loss: 57.4994\n",
      "Epoch 37/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 57.2473\n",
      "Epoch 38/80\n",
      "5/5 [==============================] - 0s 974us/step - loss: 56.9896\n",
      "Epoch 39/80\n",
      "5/5 [==============================] - 0s 749us/step - loss: 56.7316\n",
      "Epoch 40/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.4812\n",
      "Epoch 41/80\n",
      "5/5 [==============================] - 0s 888us/step - loss: 56.2208\n",
      "Epoch 42/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 55.9600\n",
      "Epoch 43/80\n",
      "5/5 [==============================] - 0s 125us/step - loss: 55.7073\n",
      "Epoch 44/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 55.4591\n",
      "Epoch 45/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 55.1893\n",
      "Epoch 46/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.9426\n",
      "Epoch 47/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 54.6866\n",
      "Epoch 48/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 54.4258\n",
      "Epoch 49/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 54.1764\n",
      "Epoch 50/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 53.9164\n",
      "Epoch 51/80\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 53.6628\n",
      "Epoch 52/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 53.4030\n",
      "Epoch 53/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 53.1473\n",
      "Epoch 54/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.8930\n",
      "Epoch 55/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.6369\n",
      "Epoch 56/80\n",
      "5/5 [==============================] - 0s 903us/step - loss: 52.3821\n",
      "Epoch 57/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 52.1265\n",
      "Epoch 58/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.8707\n",
      "Epoch 59/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 51.6138\n",
      "Epoch 60/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.3547\n",
      "Epoch 61/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.0982\n",
      "Epoch 62/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.8497\n",
      "Epoch 63/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 50.5936\n",
      "Epoch 64/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 50.3330\n",
      "Epoch 65/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.0745\n",
      "Epoch 66/80\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.8230\n",
      "Epoch 67/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.5635\n",
      "Epoch 68/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 49.3096\n",
      "Epoch 69/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 49.0537\n",
      "Epoch 70/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 48.8000\n",
      "Epoch 71/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.5428\n",
      "Epoch 72/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.2870\n",
      "Epoch 73/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.0276\n",
      "Epoch 74/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 47.7787\n",
      "Epoch 75/80\n",
      "5/5 [==============================] - 0s 0s/step - loss: 47.5169\n",
      "Epoch 76/80\n",
      "5/5 [==============================] - 0s 937us/step - loss: 47.2584\n",
      "Epoch 77/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.0051\n",
      "Epoch 78/80\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.7508\n",
      "Epoch 79/80\n",
      "5/5 [==============================] - 0s 471us/step - loss: 46.4893\n",
      "Epoch 80/80\n",
      "5/5 [==============================] - 0s 125us/step - loss: 46.2368\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(xs, ys, batch_size=batch_size, epochs=epochs, \n",
    "                    callbacks=[weight_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dc1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.6988332]], dtype=float32), array([0.40499827], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(weights_dict[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e47915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "835bde96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Epoch:  4 \n",
      "Weight:  [0.6988332]  bias:  [[0.70384777]]\n"
     ]
    }
   ],
   "source": [
    "epoch = 4\n",
    "print(\"*** Epoch: \", epoch, \"\\nWeight: \", weights_dict[0][0][0], \" bias: \", weights_dict[1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01cc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Explainable AI)",
   "language": "python",
   "name": "pycharm-63b57c3a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
